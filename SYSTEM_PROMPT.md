# System Prompt fÃ¶r Invoice Scanner Projekt

## ğŸ¯ CURRENT STATUS (Dec 26, 2025 - ~21:30)

**Overall Progress:** 90% Complete (pg8000 Migration Complete - Cloud SQL Initialized - GitHub Actions Automated Deployment Starting)

| FASE | Status | Details |
|------|--------|---------|
| FASE 0 | âœ… 100% | GCP Infrastructure (APIs, Service Accounts, GitHub Secrets) |
| FASE 1 | âœ… 100% | GCP Secret Manager (12 secrets: db_password, secret_key, gmail, openai) |
| FASE 2 | âœ… 100% | Cloud SQL (PostgreSQL instances initialized + schemas deployed) |
| FASE 3 | âœ… 100% | Docker Images (api, frontend, worker - pushed to both registries) |
| FASE 4 | âœ… 100% | GitHub Actions: Single unified pipeline.yml with conditional jobs |
| FASE 4B | âœ… 100% | Local Docker-Compose: Tested and verified, port standardization |
| FASE 4C | âœ… 100% | Database Driver Migration: pg8000 unified driver (COMPLETED & tested) |
| FASE 5 | â³ 20% | Cloud Run Deployment (Database initialized - GitHub Actions deployment starting) |
| FASE 6-8 | 0% | Cloud Tasks, Testing, Monitoring |

**Session Dec 26 - pg8000 Migration Complete**

âœ… **MIGRATION COMPLETED:**
- Successfully migrated from psycopg2 to pg8000 (Pure Python PostgreSQL driver)
- pg8000 is only driver supported by Cloud SQL Connector (pymysql, pg8000, pytds)
- Unified database configuration: all modules now use pg8000
- Standardized environment variables: all use DATABASE_* naming convention (no DB_* mixing)

âœ… **Implementation Completed:**
1. âœ… Created pg8000_wrapper.py with RealDictCursor compatibility in both API and Processing
2. âœ… Updated requirements.txt: removed psycopg2-binary, added pg8000
3. âœ… API db_config.py already using DATABASE_* variables
4. âœ… Processing config/db_utils.py already using DATABASE_* variables
5. âœ… docker-compose.yml already standardized to DATABASE_* naming

âœ… **Local Testing Verified:**
- All 14 containers start and become healthy
- API connects to database via pg8000 TCP (log: "Using pg8000 TCP connection")
- Processing workers connect and ready for tasks
- pg8000_wrapper RealDictCursor compatibility layer working
- Document processing successful (status updates working)
- Git committed with detailed message (commit: 03db1c6)

**Next:** Automated GitHub Actions deployment starting (Option A - push to re_deploy_start branch to trigger build + deploy-test)

---

## Kritiska Instruktioner fÃ¶r AI-assistenten

### 1. UNDERSÃ–K FÃ–RST - SKAPA SIST
**ALDRIG** bÃ¶rja skapa filer, dockerfiler, konfigurationer eller strukturer utan att fÃ¶rst:
- âœ… LÃ¤sa vad som redan finns (`ls -la`, `find`, `cat`)
- âœ… FÃ¶rstÃ¥ den befintliga arkitekturen
- âœ… Checka `git status` och befintliga branches
- âœ… **FRÃ…GA ANVÃ„NDAREN** vad som redan Ã¤r gjort innan du bÃ¶rjar

### 2. FRÃ…GA INNAN DU GÃ–R KAOS
Om du tÃ¤nker skapa:
- Flera konfigurationsfiler (docker-compose.yml, .env-filer, etc.)
- Deployment-strukturer eller GitHub Actions
- Stora config-system
- Dokumentation

**FRÃ…GA ALLTID ANVÃ„NDAREN:**
```
Innan jag bÃ¶rjar, vill du att jag ska:
1. [Alternativ A]
2. [Alternativ B]
3. [Alternativ C]

Eller har du redan nÃ¥got specifikt i Ã¥tanke?
```

### 3. GREP OCH EXAMINE FÃ–RST
Innan Ã¤ndringar i existerande kod:
```bash
# Checka vad som redan finns
grep -r "docker-compose" .
grep -r "ENVIRONMENT" .
git log --oneline -10

# FÃ¶rstÃ¥ arkitekturen
find . -name "*.yml" -o -name "*.yaml" | head -20
find . -name "Dockerfile*" | head -20
find . -name "requirements.txt" | head -20
```

### 4. RESPEKTERA BEFINTLIGA DECISIONS
- Om det redan finns en docker-compose.yml â†’ modifiera, inte skapa nya
- Om det redan finns en Dockerfile-struktur â†’ fÃ¶lj samma mÃ¶nster
- Om det redan finns en requirements.txt â†’ checka innehÃ¥llet innan du lÃ¤gger till
- Om det redan finns ett branch-system â†’ fÃ¶rstÃ¥ namngivningen

### 5. DOKUMENTERA VALEN
NÃ¤r du gÃ¶r Ã¤ndringar, fÃ¶rklara:
- âœ… VAD du gjorde
- âœ… VARFÃ–R du gjorde det sÃ¥
- âœ… VAD som redan fanns
- âœ… VAD som Ã¤r nÃ¤sta steg

### 6. FELLA FÃ„LLORNA
**GÃ–R INTE:**
- Skapa 16+ deployment-filer pÃ¥ gut kÃ¤nsla
- Implementera komplexe system utan att frÃ¥ga fÃ¶rst
- Ignorera att `docker-compose.local.yml` redan kan existera
- Anta att anvÃ¤ndaren vill ha Path A/B/C utan att frÃ¥ga

### 7. EFTER VARJE OPERATION
- LÃ¤s denna fil och se till att hÃ¥lla kritiska instruktioner i minnet.
- **SPECIELL UPPMÃ„RKSAMHET:** Se avsnittet "DATABASE DRIVER STRATEGY: pg8000 Migration"
- Kolla Current Status fÃ¶r vad som Ã¤r KLART vs â³ vs âŒ

**GÃ–R:**
- UndersÃ¶k fÃ¶rst
- FrÃ¥ga
- VÃ¤nd pÃ¥ tanken om det redan finns en bÃ¤ttre lÃ¶sning
- Respektera befintliga design-beslut

### 8. KRITISKA REGLER FÃ–R pg8000 MIGRATIONEN (Dec 26)

**ALDRIG implementera pg8000-migrationen utan att:**
1. âœ… LÃ¤sa ALLA filer som anvÃ¤nder `psycopg2.connect()` eller `RealDictCursor`
2. âœ… FÃ¶rstÃ¥ hur RealDictCursor anvÃ¤nds i varje fil
3. âœ… Grep-a fÃ¶r alla `DB_*` och `DATABASE_*` environment variables
4. âœ… Verifiera att docker-compose.yml fÃ¥r samma update
5. âœ… Testa lokalt med alla 13 containers innan Cloud Run
6. âœ… **HÃ…LLA ENHETLIGHET:** Inte blanda DATABASE_* och DB_* naming

**GÃ–R:**
- Refactor systematiskt (API â†’ Processing â†’ docker-compose)
- Test lokalt efter VARJE steg
- BekrÃ¤fta att RealDictCursor wrapper fungerar identiskt
- Dokumentera Ã¤ndringar i git commits

**GÃ–R INTE:**
- Implementera endast halva migrationen
- Blanda gamla och nya environment variable-namn
- Hoppa Ã¶ver processing-modulen
- FÃ¶rvÃ¤nta Cloud Run att fungera innan lokal test Ã¤r klar

## Projekt-specifikt

### Invoice Scanner Status
- **Repo:** https://github.com/Rickard-E-Strawbay/invoice.scanner
- **Branch-struktur:** main (production), re_deploy_start (current development)
- **Huvuddelar:** API (Flask), Frontend (React), Processing (Workers)
- **Docker:** AnvÃ¤nder docker-compose.yml (INTE docker-compose.local.yml)

### Innan du skapar nÃ¥got deployment/GCP-relaterat:
1. FRÃ…GA vad som redan Ã¤r gjort
2. LÃ¤s deployment/ om det finns
3. Checka .github/workflows om GitHub Actions redan finns
4. FrÃ¥ga om vilken PATH (A/B/C) eller approach anvÃ¤ndaren vill ha

### Filer att ALDRIG skapa utan att frÃ¥ga:
- Nya docker-compose*.yml
- .env-filer eller .env.*
- Deployment-manualer (15000+ ord)
- GitHub Actions workflows
- Hela config-system (invoice.scanner.api/config/)

## AnvÃ¤ndarens Preferenser
- Vill ha ENKLA lÃ¶sningar fÃ¶rst
- Vill att jag ska FRÃ…GA innan komplexitet
- Gillar TYDLIGA instruktioner
- Vill FÃ–RSTÃ… vad som gÃ¶rs, inte bara att det gÃ¶rs

---

## GCP DEPLOYMENT ARKITEKTUR & STRATEGI

### Infrastruktur-beslut (GODKÃ„ND av anvÃ¤ndare)

**Secrets Management:**
- âœ… GitHub Secrets: Endast `GCP_SA_KEY` (Service Account JSON)
- âœ… GCP Secret Manager: Alla application secrets (DB passwords, API keys, etc.)
- Full audit trail + rotation via GCP

**Databas:**
- âœ… Cloud SQL PostgreSQL (test + prod)
- Private networking (inte exponerat)
- Automatisk backup pÃ¥ prod

**Deployment-modell:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API + Frontend: Cloud Run (persistent)         â”‚
â”‚  - Alltid tillgÃ¤nglig                           â”‚
â”‚  - Auto-scaling pÃ¥ trafik                       â”‚
â”‚  - ~$10-50/mÃ¥nad fÃ¶r lÃ¥g trafik                 â”‚
â”‚                                                 â”‚
â”‚  Workers: Serverless (on-demand)                â”‚
â”‚  - Preprocessing, OCR, LLM, Extraction         â”‚
â”‚  - Cloud Tasks + Cloud Pub/Sub                 â”‚
â”‚  - Betala bara per execution                   â”‚
â”‚                                                 â”‚
â”‚  Data: Cloud SQL + Cloud Storage               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## CI/CD PIPELINE - DETALJERAD DEFINITION (v3 - UNIFIED - Dec 25)

### Branch-strategi (PR-baserad sÃ¤kerhet)

```
1. Developer creates feature branch
   â””â”€ git checkout -b feature/my-feature
   
2. Developer pushes and creates Pull Request against re_deploy_start
   â””â”€ GitHub: Requires 1 approval
   â””â”€ GitHub: PR must be reviewed

3. Reviewer approves PR
   â””â”€ Developer merges to re_deploy_start

4. After merge to re_deploy_start:
   â””â”€ pipeline.yml:build triggers automatically (push event)
   â””â”€ Auto-detects branch = re_deploy_start
   â””â”€ Builds images, pushes to TEST Artifact Registry
   â””â”€ pipeline.yml:deploy-test triggers automatically (after build)
   â””â”€ Deploys to TEST Cloud Run
   â””â”€ Smoke tests run
   â””â”€ âœ… TEST environment live

5. For PROD: Developer creates PR main â† re_deploy_start
   â””â”€ GitHub: Requires 1-2 approvals
   â””â”€ GitHub: PR must be reviewed

6. Reviewer approves PROD PR
   â””â”€ Developer merges to main

7. After merge to main:
   â””â”€ pipeline.yml:build triggers automatically (push event)
   â””â”€ Auto-detects branch = main
   â””â”€ Builds images, pushes to PROD Artifact Registry
   â””â”€ pipeline.yml:deploy-prod job appears (waiting)
   â””â”€ âš ï¸ MANUAL APPROVAL GATE (GitHub environment: "production")
   â””â”€ Admin/Reviewer clicks "Approve" in GitHub UI
   â””â”€ pipeline.yml:deploy-prod resumes (24h timeout)
   â””â”€ Deploys to PROD Cloud Run
   â””â”€ Smoke tests run
   â””â”€ âœ… PROD environment live
```

### GitHub Actions Workflows (1 file, 3 conditional jobs - FINAL)

**File:** `.github/workflows/pipeline.yml`

**Structure:**
```yaml
on:
  push:
    branches: [re_deploy_start, main]

jobs:
  build: ...              # Always runs (detects branch)
  deploy-test: ...        # Runs only on re_deploy_start (needs: build)
  deploy-prod: ...        # Runs only on main (needs: build, environment: production)
```

#### 1ï¸âƒ£ build job - Build & Push Docker Images (UNIFIED)
**Triggers:** Push to `re_deploy_start` OR `main`

**Auto-detects branch and uses correct GCP project:**
```yaml
Branch detection logic (in first step):
  if github.ref == 'refs/heads/main' 
    â†’ use GCP_SA_KEY_PROD 
    â†’ push to strawbayscannerprod registry
  
  else (re_deploy_start)
    â†’ use GCP_SA_KEY_TEST 
    â†’ push to strawbayscannertest registry
```

**Docker images som byggs:**
- `api:latest` & `api:{git-sha}` 
- `frontend:latest` & `frontend:{git-sha}`
- `worker:latest` & `worker:{git-sha}` (optional)

**Push location (auto-detected):**
- TEST-projekt: `europe-west1-docker.pkg.dev/strawbayscannertest/invoice-scanner/`
- PROD-projekt: `europe-west1-docker.pkg.dev/strawbayscannerprod/invoice-scanner/`

**Steps i build job:**
```yaml
1. Checkout code
2. Detect branch â†’ determine GCP project + registry + SA key
3. Authenticate to Google Cloud (GCP_SA_KEY_TEST or GCP_SA_KEY_PROD)
4. Configure Docker authentication to Artifact Registry
5. Build API image:     docker build â†’ tag latest + sha â†’ push
6. Build Frontend image: docker build â†’ tag latest + sha â†’ push
7. Build Worker image:   docker build â†’ tag latest + sha â†’ push (if exists)
8. Build summary: Show which environment + registry used
```

**Outputs from build:**
- `registry` - Which Artifact Registry used
- `environment` - "test" or "prod"
- `gcp_project` - Project ID used

#### 2ï¸âƒ£ deploy-test job - Deploy to TEST (Conditional on re_deploy_start)
**Triggers:** After pipeline.yml:build completes, ONLY if on `re_deploy_start`
**Condition:** `if: github.ref == 'refs/heads/re_deploy_start'`
**Environment:** GitHub environment "test" (no approval required)
**Dependencies:** `needs: build`

**What it does:**
1. Waits for build job to complete
2. Only runs if branch is re_deploy_start
3. Authenticates to GCP TEST project
4. Fetches 5 secrets from GCP Secret Manager (test project)
5. Deploys invoice-scanner-api-test to Cloud Run
6. Deploys invoice-scanner-frontend-test to Cloud Run
7. Runs smoke tests (curl /health endpoint)
8. Outputs service URLs

**Configuration:**
- Memory: API 512Mi, Frontend 256Mi
- CPU: 1 for each
- Max instances: 10 each
- Environment variables: Auto-injected from GCP secrets

#### 3ï¸âƒ£ deploy-prod job - Deploy to PROD (Conditional on main, with manual approval)
**Triggers:** After pipeline.yml:build completes, ONLY if on `main`
**Condition:** `if: github.ref == 'refs/heads/main'`
**Environment:** GitHub environment "production" (REQUIRES manual approval)
**Dependencies:** `needs: build`

**What it does:**
1. Waits for build job to complete
2. Only runs if branch is main
3. âš ï¸ PAUSES and waits for manual approval (24h timeout)
4. After approval: Authenticates to GCP PROD project
5. Fetches 5 secrets from GCP Secret Manager (prod project)
6. Deploys invoice-scanner-api-prod to Cloud Run
7. Deploys invoice-scanner-frontend-prod to Cloud Run
8. Runs smoke tests
9. Outputs service URLs

**Configuration:**
- Memory: API 512Mi, Frontend 256Mi
- CPU: 1 for each
- Min instances: 1 each (always running - cheaper idle state)
- Max instances: 20 each (auto-scale under load)
- Environment variables: Auto-injected from GCP secrets (prod variants)

### Arkitektur-diagram (UPDATED - UNIFIED)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GitHub                                   â”‚
â”‚  main (prod) â†â”€ Pull Request â† re_deploy_start (dev)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                       â”‚
                     â”‚ Push to main          â”‚ Push to re_deploy_start
                     â”‚                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   pipeline.yml      â”‚   â”‚   pipeline.yml        â”‚
         â”‚   :build job        â”‚   â”‚   :build job          â”‚
         â”‚ (GCP_SA_KEY_PROD)   â”‚   â”‚ (GCP_SA_KEY_TEST)     â”‚
         â”‚ Build & Push Images â”‚   â”‚ Build & Push Images   â”‚
         â”‚ to PROD registry    â”‚   â”‚ to TEST registry      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Artifact Registry  â”‚   â”‚ Artifact Registry    â”‚
         â”‚   PROD Project      â”‚   â”‚  TEST Project        â”‚
         â”‚  (eu-west1 repo)    â”‚   â”‚  (eu-west1 repo)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  pipeline.yml         â”‚   â”‚  pipeline.yml      â”‚
         â”‚  :deploy-prod job     â”‚   â”‚  :deploy-test job  â”‚
         â”‚ (requires approval!)  â”‚   â”‚ (auto-run)         â”‚
         â”‚                       â”‚   â”‚                    â”‚
         â”‚ âš ï¸ MANUAL APPROVAL    â”‚   â”‚ Fetch secrets_test â”‚
         â”‚ GATE (24h timeout)    â”‚   â”‚ Deploy to TEST     â”‚
         â”‚ <CLICK "APPROVE">     â”‚   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚         â”‚
         â”‚ After approval:       â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Fetch secrets_prod    â”‚    â”‚  TEST Cloud Run   â”‚
         â”‚ Deploy to PROD        â”‚    â”‚  - api-test       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  - frontend-test  â”‚
                    â”‚                 â”‚ Smoke tests OK    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚  PROD Cloud Run     â”‚
         â”‚  - api-prod         â”‚
         â”‚  - frontend-prod    â”‚
         â”‚ Smoke tests OK      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key points:**
- âœ… Single `pipeline.yml` file (not 3 separate files)
- âœ… All jobs in one place
- âœ… Branch detection in first step of build job
- âœ… deploy-test runs ONLY if branch is re_deploy_start
- âœ… deploy-prod runs ONLY if branch is main (with approval)
- âœ… Clean, maintainable, no duplication

### Secret Manager Mapping

**GCP Secret Manager â†’ Environment Variables:**

TEST-projekt (`strawbayscannertest`):
```
Secret name              â†’ Env var               â†’ AnvÃ¤nds i
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
db_user_test            â†’ DATABASE_USER         â†’ Cloud Run API
db_password_test        â†’ DATABASE_PASSWORD     â†’ Cloud Run API
secret_key_test         â†’ FLASK_SECRET_KEY      â†’ Cloud Run API
gmail_sender            â†’ EMAIL_SENDER          â†’ Cloud Run API
gmail_password          â†’ EMAIL_PASSWORD        â†’ Cloud Run API
openai_api_key          â†’ OPENAI_API_KEY        â†’ Cloud Run API
```

PROD-projekt (`strawbayscannerprod`):
```
Secret name              â†’ Env var               â†’ AnvÃ¤nds i
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
db_user_prod            â†’ DATABASE_USER         â†’ Cloud Run API
db_password_prod        â†’ DATABASE_PASSWORD     â†’ Cloud Run API
secret_key_prod         â†’ FLASK_SECRET_KEY      â†’ Cloud Run API
gmail_sender            â†’ EMAIL_SENDER          â†’ Cloud Run API
gmail_password          â†’ EMAIL_PASSWORD        â†’ Cloud Run API
openai_api_key          â†’ OPENAI_API_KEY        â†’ Cloud Run API
```

### GitHub Environments (Manual Approval)

**GitHub â†’ Settings â†’ Environments:**

Skapa tvÃ¥ environments:
```
test
â”œâ”€ Deployment branches: re_deploy_start, feature/*
â””â”€ No approval needed

production
â”œâ”€ Deployment branches: main
â”œâ”€ Required reviewers: (Rickard)
â””â”€ Timeout: 24 hours
```

**I pipeline.yml (deploy-prod job):**
```yaml
environment:
  name: production
  url: https://api-prod-xxxxx.run.app
```

---

### Complete CI/CD Flow Exempel (UNIFIED PIPELINE)

**Scenario: Utvecklare pushar feature**

```
1. Utvecklare: git push origin my-feature
2. GitHub: Ã–ppnar PR mot re_deploy_start
3. GitHub: CI-checks kÃ¶r linting, tester, etc
4. Utvecklare/Reviewer: Merge PR
5. GitHub: Detekterar push till re_deploy_start
6. pipeline.yml:build: 
   - Detekterar branch = re_deploy_start
   - AnvÃ¤nder GCP_SA_KEY_TEST
   - Bygger api:latest, frontend:latest, worker:latest
   - Pushar till strawbayscannertest Artifact Registry
7. pipeline.yml:deploy-test (auto-trigger efter build):
   - Villkor: if: github.ref == 'refs/heads/re_deploy_start'
   - KÃ¶r automatiskt (no approval needed)
   - AnvÃ¤nder GCP_SA_KEY_TEST
   - HÃ¤mtar 5 secrets frÃ¥n TEST Secret Manager
   - Deployar till Cloud Run services
   - KÃ¶r smoke tests
8. Utvecklare testar pÃ¥: api-test-xxxxx.run.app
```

**Scenario: Merge till main (PROD deployment)**

```
1. PR merged in GitHub â†’ main
2. GitHub: Detekterar push till main
3. pipeline.yml:build: 
   - Detekterar branch = main
   - AnvÃ¤nder GCP_SA_KEY_PROD
   - Bygger och pushar till strawbayscannerprod Artifact Registry
4. pipeline.yml:deploy-prod-job: PAUSES och vÃ¤ntar pÃ¥ approval
   - Villkor: if: github.ref == 'refs/heads/main' + environment: production
   - GitHub visar: "This job requires manual approval"
   - Timeout: 24 timmar
5. Rickard loggar in i GitHub Actions UI
   - Ser deploy-prod job i Pending state
   - Klickar "Review deployments" â†’ "production" â†’ "Approve and deploy"
6. pipeline.yml:deploy-prod (resumed):
   - AnvÃ¤nder GCP_SA_KEY_PROD
   - HÃ¤mtar 5 secrets frÃ¥n PROD Secret Manager
   - Deployar till Cloud Run (prod services)
   - KÃ¶r smoke tests
7. Live pÃ¥: api-prod-xxxxx.run.app
```

---

## IMPLEMENTATION CHECKLISTA

### FASE 0: Setup (NÃ„STA - 0% done)
- [ ] GCP Project IDs dokumenterade
- [ ] Aktivera APIs: Cloud Run, Cloud SQL, Artifact Registry, Secret Manager, Cloud Tasks
- [ ] Service Accounts skapade (test + prod)
- [ ] GitHub Secrets konfigurerad: `GCP_SA_KEY`

### FASE 1: GCP Secret Manager (0% done)
- [ ] Skapa secrets i GCP Secret Manager (test project):
  - `db_password`, `db_user`, `api_key`, `gmail_password`, etc.
- [ ] Samma secrets i prod project
- [ ] Testa lÃ¤sning frÃ¥n GitHub Actions

### FASE 2: Cloud SQL Setup (0% done)
- [ ] Skapa PostgreSQL instans (test)
  - Name: `invoice-scanner-test`
  - Network: Private IP
- [ ] Skapa PostgreSQL instans (prod)
  - Name: `invoice-scanner-prod`
  - Backup enabled
- [ ] KÃ¶r init.sql pÃ¥ bÃ¥da
- [ ] Verifiera anslutning frÃ¥n Cloud Run

### FASE 3: Docker Images âœ… 100% KLART

**Docker Images Built & Pushed to Artifact Registry:**

TEST-projekt (`strawbayscannertest`):
```
âœ… europe-west1-docker.pkg.dev/strawbayscannertest/invoice-scanner/api:latest
âœ… europe-west1-docker.pkg.dev/strawbayscannertest/invoice-scanner/frontend:latest
âœ… europe-west1-docker.pkg.dev/strawbayscannertest/invoice-scanner/worker:latest
```

PROD-projekt (`strawbayscannerprod`):
```
âœ… europe-west1-docker.pkg.dev/strawbayscannerprod/invoice-scanner/api:latest
âœ… europe-west1-docker.pkg.dev/strawbayscannerprod/invoice-scanner/frontend:latest
âœ… europe-west1-docker.pkg.dev/strawbayscannerprod/invoice-scanner/worker:latest
```

**Image Details:**
- API: 1.44 GB (python:3.11-slim, Flask, optimized dependencies)
- Frontend: 83.1 MB (Node 20-alpine builder + nginx multi-stage)
- Worker: 4.02 GB (python:3.11-bullseye + OCR dependencies)

**Pushed:** Dec 24, 2025
**Status:** All 6 images successfully pushed to both registries

### FASE 4: GitHub Actions Workflows âœ… 100% KLART

**Single Unified Pipeline:** `.github/workflows/pipeline.yml`
- âœ… build job - Detects branch, builds 3 images, pushes to correct registry
- âœ… deploy-test job - Conditional on re_deploy_start, no approval needed
- âœ… deploy-prod job - Conditional on main, requires `environment: production` approval
- âœ… All 3 jobs in one file for maintainability
- âœ… Branch detection logic in build job first step
- âœ… Jobs properly chain with `needs: build` dependency
- âœ… Uses secrets: `GCP_SA_KEY_TEST` or `GCP_SA_KEY_PROD` (auto-selected)

**Cleanup completed:**
- âœ… Removed old build.yml, test-deploy.yml, prod-deploy.yml
- âœ… Removed .bak backup files
- âœ… Workflows directory now contains ONLY pipeline.yml
- âœ… Committed and pushed to origin/re_deploy_start

**Status:** All 3 conditional jobs ready to execute on branch push

**What's needed:**
- â³ User creates PR on re_deploy_start to test
- â³ First merge to re_deploy_start (pipeline.yml:build + pipeline.yml:deploy-test run)
- â³ First merge to main (pipeline.yml:build + pipeline.yml:deploy-prod with approval)

---

## DATABASE MIGRATION STRATEGY (DECIDED Dec 26)

**Decision:** Use **Versionalized SQL Migrations** approach for future database changes

### How it works:
- Each database change gets its own versioned SQL file: `migrations/001_initial.sql`, `002_add_column_x.sql`, etc.
- Files are named: `{number}_{description}.sql` (e.g., `001_initial.sql`, `002_add_invoices_table.sql`)
- Run migrations in order (only once per environment)
- Track which migrations have run in a `schema_migrations` table

### Initial Setup (Dec 26 - COMPLETED):
- [x] âœ… Run `invoice.scanner.db/init.sql` manually on Cloud SQL TEST
- [x] âœ… Verify: Check that users table has test user (rickard@strawbay.io)
- [x] âœ… Run same init.sql on PROD after TEST is verified

### Future Database Changes:
1. Create new file: `migrations/002_your_change.sql`
2. Document what changed
3. Run it manually on TEST first
4. After verification, run on PROD
5. Add to git + commit

### Directory Structure:
```
invoice.scanner.db/
â”œâ”€â”€ init.sql (initial schema + seed data)
â””â”€â”€ migrations/
    â”œâ”€â”€ 002_add_feature_x.sql
    â”œâ”€â”€ 003_update_permissions.sql
    â””â”€â”€ ...
```

---

## CLOUD SQL PROXY CONFIGURATION (DECIDED Dec 26)

**Problem (Dec 26 08:15):** Cloud Run API couldn't connect to Cloud SQL
- Error: `connection to server at "invoice-scanner-test.c.strawbayscannertest.cloudsql.googleapis.com" port 5432 failed: Connection timed out`
- Root cause: Cloud SQL is Private IP only, API tried public hostname

**Solution:** Cloud SQL Auth Proxy sidecar in Cloud Run
- Already configured in pipeline.yml with `--add-cloudsql-instances` flag
- Creates secure tunnel from Cloud Run container to Cloud SQL
- Exposes connection on `localhost:5432`

**Implementation (Dec 26):**
1. âœ… pipeline.yml already has `--add-cloudsql-instances` flag in both deploy-test and deploy-prod
2. âœ… Changed DATABASE_HOST from `invoice-scanner-test.c.strawbayscannertest.cloudsql.googleapis.com` to `localhost`
3. âœ… Same for PROD: `invoice-scanner-prod.c.strawbayscannerprod.cloudsql.googleapis.com` â†’ `localhost`
4. Rationale: Cloud SQL Proxy maps port 5432 to localhost internally

**Environment Variables in Cloud Run:**
```
TEST:
  DATABASE_HOST=localhost (with Cloud SQL Proxy sidecar)
  DATABASE_PORT=5432
  DATABASE_USER=scanner_test
  DATABASE_PASSWORD=(from Secret Manager)
  DATABASE_NAME=invoice_scanner

PROD: (same pattern)
  DATABASE_HOST=localhost
  DATABASE_PORT=5432
  DATABASE_USER=scanner_prod
  DATABASE_PASSWORD=(from Secret Manager)
  DATABASE_NAME=invoice_scanner
```

**How it works:**
1. Cloud Run container starts with `--add-cloudsql-instances=project:region:instance`
2. Google Cloud Proxy sidecar automatically starts (injected by Cloud Run)
3. Proxy creates secure connection to Cloud SQL (Private IP)
4. Proxy listens on `localhost:5432` inside container
5. Application connects to `localhost:5432` (authenticated via Cloud Run service account)

**Reference:**
- [Google Cloud SQL Auth Proxy Docs](https://cloud.google.com/sql/docs/postgres/sql-proxy)
- [Cloud Run + Cloud SQL Integration](https://cloud.google.com/run/docs/configuring/sql-connectors)

**Status:** âœ… CONFIGURED in pipeline.yml (both TEST and PROD)

---

## DATABASE DRIVER STRATEGY: pg8000 Migration (DECIDED Dec 26)

### Problem Discovery (Dec 26 - CRITICAL)

**Error in Cloud Run logs (10:00:39):**
```
"Driver 'psycopg2' is not supported."
```

**Root Cause Investigation:**
- Cloud SQL Connector API documentation discovered: Only supports `pymysql`, `pg8000`, `pytds`
- psycopg2 is NOT supported by Cloud SQL Connector
- Current code attempted: `connector.connect(..., "psycopg2", ...)`
- This was doomed to fail in Cloud Run

**Architecture Issue (SIMULTANEOUS DISCOVERY):**
- API uses `DATABASE_*` environment variables
- Processing uses `DB_*` environment variables (old naming convention)
- Two separate database connection systems in same project
- Cannot fix one without fixing both

### Solution: Unified pg8000 Strategy

**Why pg8000?**
- âœ… Pure Python PostgreSQL driver (no C dependencies)
- âœ… Cloud SQL Connector officially supports it
- âœ… Works with local TCP connections (docker-compose)
- âœ… Works with future Connector mode in Cloud Run
- âœ… Single solution for all environments

**Challenges:**
- pg8000 doesn't have `RealDictCursor` built-in (like psycopg2)
- Current codebase heavily uses RealDictCursor for dictionary-like row access
- Solution: Create wrapper layer providing RealDictCursor interface for pg8000

### Implementation Plan (3-Part Refactoring)

**Part 1: Create Shared Database Abstraction Layer**
- Location: `/shared/pg8000_wrapper.py`
- Provides: `RealDictCursor`-like interface for pg8000 rows
- Supports: Both local TCP (docker-compose) and future Connector mode (Cloud Run)
- Implements: Connection pooling for efficiency

**Part 2: Standardize Environment Variables Across Entire Project**
- Converge: `DB_*` variables â†’ `DATABASE_*` (uniform naming)
- Files affected:
  - `invoice.scanner.api/db_config.py` - Already uses DATABASE_*
  - `invoice.scanner.api/db_utils.py` - Uses db_config imports
  - `invoice.scanner.processing/config/db_utils.py` - Uses old DB_* (needs update)
  - `docker-compose.yml` - Update all 13 services to use DATABASE_*
- Rationale: Single naming convention simplifies debugging + matches Cloud Run

**Part 3: Update Both API and Processing Modules**
- API: Refactor db_config.py to use shared pg8000 wrapper
- Processing: Update config/db_utils.py to use shared wrapper + new env vars
- Verify: All existing functionality preserved (RealDictCursor behavior replicated)
- Test: All 13 containers work locally before Cloud Run

### Critical Instructions (Must Remember)

**When implementing pg8000 migration:**

1. **INVESTIGATE FIRST**
   - Grep for all uses of `psycopg2.connect()`
   - Find all places using `RealDictCursor`
   - Check all environment variable references
   - Understand current connection patterns

2. **STANDARDIZE NAMING SYSTEMATICALLY**
   - Don't leave dual naming convention (mixing DATABASE_* and DB_*)
   - Update docker-compose.yml simultaneously
   - Verify all 13 containers get correct variables
   - No half-migrations

3. **TEST LOCALLY BEFORE CLOUD RUN**
   - Run all 13 containers with new pg8000 wrapper
   - Test API login endpoint (uses database)
   - Test processing workers (use database queries)
   - Verify RealDictCursor compatibility layer works

4. **MAINTAIN BACKWARD COMPATIBILITY**
   - Existing code should not know it's pg8000 internally
   - RealDictCursor interface must be identical to psycopg2 version
   - All cursors should still behave like dictionaries

### Current Status (Dec 26 - Migration Complete âœ…)

**Completed (ALL):**
- âœ… Identified driver incompatibility (psycopg2 not supported by Cloud SQL Connector)
- âœ… Analyzed entire project structure (unified pg8000 approach)
- âœ… Created pg8000_wrapper.py with RealDictCursor compatibility in API and Processing
- âœ… Updated requirements.txt: Removed psycopg2-binary, added pg8000
- âœ… API db_config.py configured for pg8000 (DATABASE_* variables)
- âœ… Processing config/db_utils.py configured for pg8000 (DATABASE_* variables)
- âœ… docker-compose.yml standardized to DATABASE_* naming (no DB_* mixing)
- âœ… Local testing: all 14 containers healthy, database connections working
- âœ… Document processing verified (status updates working correctly)
- âœ… Git commit with detailed migration message (commit: 03db1c6)

**Status:** READY FOR CLOUD RUN DEPLOYMENT
- All components use unified pg8000 driver
- Both local (docker-compose) and Cloud Run (via Connector) compatible
- RealDictCursor compatibility maintained for existing code
- No psycopg2 dependencies remaining

---

### FASE 5: Cloud Run Deployment (GitHub Actions Automated Deployment)
- [x] âœ… Database schema initialized (init.sql deployed to Cloud SQL TEST + PROD)
- [x] âœ… Cloud SQL Proxy configured in pipeline.yml (DATABASE_HOST=localhost)
- [x] âœ… init.sql run manually on Cloud SQL
- [ ] â³ Push to re_deploy_start branch (triggers GitHub Actions)
- [ ] â³ GitHub Actions:build job - builds 3 Docker images, pushes to TEST registry
- [ ] â³ GitHub Actions:deploy-test job - auto-deploys to Cloud Run TEST
- [ ] â³ Test login flow (API â†’ Cloud SQL connectivity in Cloud Run)
- [ ] Verify: API service running on Cloud Run TEST
- [ ] Verify: Frontend service running on Cloud Run TEST
- [ ] Setup Cloud Storage bucket (documents)
- [ ] Create PR: re_deploy_start â†’ main (for PROD deployment)

### FASE 6: Cloud Tasks Setup (0% done)
- [ ] Konfigurera Cloud Tasks queue fÃ¶r workers
- [ ] Cloud Pub/Sub topics fÃ¶r events
- [ ] Worker-container ready fÃ¶r on-demand execution

### FASE 7: Testing & Verification (0% done)
- [ ] Test pipeline frÃ¥n GitHub push
- [ ] Manual approval flow testat
- [ ] Smoke tests pÃ¥ Cloud Run services
- [ ] Database connectivity verified
- [ ] Secrets lÃ¤ses korrekt

### FASE 8: Monitoring & Alerts (0% done)
- [ ] Google Cloud Logging configured
- [ ] Error alerts setup
- [ ] Performance monitoring
- [ ] Backup verification (prod)

---

## GCP PROJEKT KONFIGURATION

**GCP Project IDs:**
- âœ… Test: `strawbayscannertest`
- âœ… Prod: `strawbayscannerprod`

**Region:**
- âœ… `europe-west1` (Belgien)

**URLs:**
- âœ… GCP-genererade URLs (ex: `api-xxxxx.run.app`)

## GCP SECRETS STRATEGI (GODKÃ„ND)

**GitHub Secrets (Option A - TvÃ¥ separata):**
- `GCP_SA_KEY_TEST` â†’ Service Account JSON frÃ¥n TEST-projekt
- `GCP_SA_KEY_PROD` â†’ Service Account JSON frÃ¥n PROD-projekt

**VarfÃ¶r tvÃ¥:** CI/CD pipeline kan automatiskt vÃ¤lja rÃ¤tt secret baserat pÃ¥ miljÃ¶ (test branch â†’ TEST secret, main branch â†’ PROD secret)

**SÃ¤kerhet:**
- âœ… Aldrig lagra secrets i kod
- âœ… GitHub Secrets Ã¤r encrypted
- âœ… Loggar visar inte secret-vÃ¤rden
- âœ… Endast Actions kan lÃ¤sa secrets under kÃ¶rning

---

## GCP SETUP STATUS - FASE 0: âœ… 100% KLART

**APIs Aktiverade: âœ… KLART**
- âœ… TEST-projekt: Alla 5 APIs enabled
- âœ… PROD-projekt: Alla 5 APIs enabled

**Service Accounts: âœ… KLART**
- âœ… TEST-projekt: `github-deployer` skapad (Editor role)
- âœ… PROD-projekt: `github-deployer` skapad (Editor role)

**JSON-Nycklar: âœ… KLART**
- âœ… TEST-projekt: JSON-nyckel nedladdad
- âœ… PROD-projekt: JSON-nyckel nedladdad

**GitHub Secrets: âœ… KLART**
- âœ… `GCP_SA_KEY_TEST` â†’ Ligger i GitHub
- âœ… `GCP_SA_KEY_PROD` â†’ Ligger i GitHub

**Progress FASE 0:**
- âœ… [x] APIs aktiverade (test + prod)
- âœ… [x] Service Accounts skapade (test + prod)
- âœ… [x] JSON-nycklar exporterade (test + prod)
- âœ… [x] GitHub Secrets konfigurerad (Option A)

---

## IMPLEMENTATION CHECKLISTA - UPPDATERAD

### FASE 0: Setup âœ… KLART (100%)
- âœ… GCP Project IDs dokumenterade
- âœ… Aktivera APIs: Cloud Run, Cloud SQL, Artifact Registry, Secret Manager, Cloud Tasks
- âœ… Service Accounts skapade (test + prod)
- âœ… GitHub Secrets konfigurerad: `GCP_SA_KEY_TEST` + `GCP_SA_KEY_PROD`

### FASE 1: GCP Secret Manager âœ… KLART (100%)

**Database Credentials: âœ… SKAPADE I GCP SECRET MANAGER**

TEST-projekt (`strawbayscannertest`) secrets:
- âœ… `db_user_test` = `scanner_test`
- âœ… `db_password_test` = `3ksaMsUqY5EW60FvXmp5MNv9i!mbkoQX`

PROD-projekt (`strawbayscannerprod`) secrets:
- âœ… `db_user_prod` = `scanner_prod`
- âœ… `db_password_prod` = `94LVGuefzk0g#a4Mbu2u!mu@I7R%PItl`

**Flask SECRET_KEY: âœ… SKAPADE**

TEST-projekt:
- âœ… `secret_key_test` = `cWz$o%u-Mnfse1k%bhNf3K_xRcvSeFxnHlQzgt5H!wSWYtliIB4COYyKNq7iq7Gi`

PROD-projekt:
- âœ… `secret_key_prod` = `kWKmBqNA@7WSERqjAP%E8X6ulY%cvX!!j6hUQ8DgiZqCyjq8Ag@4OTEXhx5P9LWz`

**Email Credentials: âœ… SKAPADE (samma i bÃ¥de test och prod)**

BÃ…DA projekt:
- âœ… `gmail_sender` = `rickard@strawbay.io`
- âœ… `gmail_password` = `ggse prtk gmye nrqe`

**LLM API Keys: âœ… SKAPADE (samma i bÃ¥de test och prod)**

BÃ…DA projekt:
- âœ… `openai_api_key` = (frÃ¥n Secret Manager)

**Summa FASE 1:**
- âœ… 6 secrets i TEST-projekt
- âœ… 6 secrets i PROD-projekt
- âœ… Alla anvÃ¤ndaruppgifter frÃ¥n befintlig `.env` migrerade
- âœ… Starka, genererade lÃ¶senord fÃ¶r databaskonton
- âœ… Starka, genererade Flask SECRET_KEY fÃ¶r bÃ¥da miljÃ¶er

### FASE 2: Cloud SQL Setup âœ… KLART (100%)

**TEST-projekt (`strawbayscannertest`): âœ… KLART**

PostgreSQL Instans:
- âœ… Instance name: `invoice-scanner-test`
- âœ… Machine type: db-f1-micro (Shared-core, 0.614 GB RAM)
- âœ… Region: europe-west1 (belgien)
- âœ… Private IP: Enabled
- âœ… Database: `invoice_scanner` skapad
- âœ… User: `scanner_test` skapad
- âœ… Root password: `0R@UMO1Mr-s-hKVA6Y5JwSWQUrcIY1RN`

**PROD-projekt (`strawbayscannerprod`): âœ… KLART**

PostgreSQL Instans:
- âœ… Instance name: `invoice-scanner-prod`
- âœ… Machine type: db-f1-micro (Shared-core)
- âœ… Region: europe-west1
- âœ… Private IP: Enabled
- âœ… Backup: Enabled
- âœ… Database: `invoice_scanner` skapad
- âœ… User: `scanner_prod` skapad
- âœ… Root password: `HP!#mtYvvxmGxgvJP7AynwmlBvFyGd_r`

### FASE 3: Docker Images (0% done)
- [ ] Dockerfile API: Ready fÃ¶r Cloud Run
- [ ] Dockerfile Frontend: Ready fÃ¶r Cloud Run
- [ ] Dockerfile Worker: Ready fÃ¶r Cloud Tasks
- [ ] Build & push till Artifact Registry (test fÃ¶rst)

### FASE 4: GitHub Actions Workflows (100% KLART)
- âœ… `.github/workflows/pipeline.yml` - Single file with build + conditional deploys
- âœ… build job - Auto-detects branch, builds 3 images, pushes to correct registry
- âœ… deploy-test job - Runs on re_deploy_start (no approval)
- âœ… deploy-prod job - Runs on main (requires approval)
- âœ… All jobs in one unified file

### FASE 5: Cloud Run Deployment (0% done)
- [ ] Deploy API service (test)
  - Environment variables frÃ¥n Secret Manager
  - Cloud SQL proxy
- [ ] Deploy Frontend service (test)
  - Build from Docker image
- [ ] Setup Cloud Storage bucket (documents)
- [ ] Samma setup fÃ¶r prod

### FASE 6: Cloud Tasks Setup (0% done)
- [ ] Konfigurera Cloud Tasks queue fÃ¶r workers
- [ ] Cloud Pub/Sub topics fÃ¶r events
- [ ] Worker-container ready fÃ¶r on-demand execution

### FASE 7: Testing & Verification (0% done)
- [ ] Test pipeline frÃ¥n GitHub push
- [ ] Manual approval flow testat
- [ ] Smoke tests pÃ¥ Cloud Run services
- [ ] Database connectivity verified
- [ ] Secrets lÃ¤ses korrekt

### FASE 8: Monitoring & Alerts (0% done)
- [ ] Google Cloud Logging configured
- [ ] Error alerts setup
- [ ] Performance monitoring
- [ ] Backup verification (prod)

---

### TEST-Projektet (`strawbayscannertest`)

**Aktiverade APIs:**
- âœ… Cloud Run Admin API
- âœ… Cloud SQL Admin API
- âœ… Artifact Registry API
- âœ… Secret Manager API
- âœ… Cloud Tasks API

**Service Accounts:**
- âœ… `github-deployer` (Editor role) - BehÃ¶ver JSON-nyckel

**Kommande:**
- â³ JSON-nyckel exporterad
- â³ Cloud SQL PostgreSQL instans
- â³ Cloud Storage bucket
- â³ Secret Manager secrets

---

### PROD-Projektet (`strawbayscannerprod`)

**Aktiverade APIs:**
- âœ… Cloud Run Admin API
- âœ… Cloud SQL Admin API
- âœ… Artifact Registry API
- âœ… Secret Manager API
- âœ… Cloud Tasks API

**Service Accounts:**
- âœ… `github-deployer` (Editor role) - BehÃ¶ver JSON-nyckel

**Kommande:**
- â³ JSON-nyckel exporterad
- â³ Cloud SQL PostgreSQL instans (med backup)
- â³ Cloud Storage bucket
- â³ Secret Manager secrets

---

**Summa:** UndersÃ¶k, FrÃ¥ga, Skapa. Inte: Skapa, Skapa, Skapa, sedan rÃ¤tta allt.
