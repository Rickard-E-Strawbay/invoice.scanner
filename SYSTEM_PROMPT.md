# System Prompt f√∂r Invoice Scanner Projekt

---

## üìã QUICK REFERENCE - L√§s detta f√∂rst!

| Vad | Status | Vad g√∂r vi |
|-----|--------|-----------|
| **Local Docker** | ‚úÖ Ready | Alla 14 containers bygger + health |
| **pg8000 Driver** | ‚úÖ Complete | Testad med pg8000_wrapper + RealDictCursor |
| **Database** | ‚úÖ Ready | Cloud SQL TEST+PROD initialiserad |
| **GitHub Actions** | ‚úÖ Ready | Pipeline.yml (single file, 3 jobs) |
| **GCP Secrets** | ‚úÖ Ready | 12 secrets i Secret Manager |
| **Docker Images** | ‚úÖ Ready | Api, Frontend, Worker pushed till registries |
| **Cloud Run TEST** | ‚úÖ Live | API rev 00048 + Frontend deployed & working |
| **Admin Panel** | ‚úÖ Working | User/Company management, Enable/Disable buttons |
| **NEXT STEP** | üëâ DO THIS | Test document processing (Scan service) |

**Enkelt sagt:**
- Cloud Run TEST √§r live och fungerar
- Admin panel fungerar (Enable/Disable buttons working)
- Email √§r temp disabled (SMTP kan inte n√• fr√•n Cloud Run)
- Ready to test document processing

---

**Overall Progress:** 98% Complete - Ready for Document Processing Testing

| FASE | Status | Details | Last Updated |
|------|--------|---------|--------------|
| FASE 0 | ‚úÖ 100% | GCP Infrastructure (APIs, Service Accounts, GitHub Secrets) | Dec 25 |
| FASE 1 | ‚úÖ 100% | GCP Secret Manager (12 secrets configured) | Dec 25 |
| FASE 2 | ‚úÖ 100% | Cloud SQL (PostgreSQL instances initialized + schemas deployed) | Dec 26 |
| FASE 3 | ‚úÖ 100% | Docker Images (api, frontend, worker - pushed to both registries) | Dec 24 |
| FASE 4 | ‚úÖ 100% | GitHub Actions: Single unified pipeline.yml with conditional jobs | Dec 25 |
| FASE 4B | ‚úÖ 100% | Local Docker-Compose: Fresh rebuild completed - all 14 containers healthy | Dec 26 22:30 |
| FASE 4C | ‚úÖ 100% | Database Driver Migration: pg8000 unified driver + RealDictCursor wrapper | Dec 26 |
| **FASE 5** | ‚úÖ 100% | Cloud Run Deployment (API & Frontend deployed to TEST) | **Dec 26 16:40** |
| **FASE 5A** | ‚úÖ 100% | JSON Serialization: PG8000DictRow ‚Üí dict conversion fixes | **Dec 26 16:45** |
| **FASE 5B** | ‚úÖ 100% | VPC Access Connectors: Private IP connectivity TEST+PROD | **Dec 26** |
| **FASE 5C** | ‚úÖ 100% | Session Management: Environment-aware Flask session cookies (HTTPS) | **Dec 26** |
| **FASE 5D** | ‚úÖ 100% | API Response Fields: company_enabled added to user responses | **Dec 26 16:32** |
| **FASE 5E** | ‚úÖ 100% | Email Service: Disabled in Cloud Run (pending SendGrid migration) | **Dec 26 16:40** |
| FASE 6 | ‚è≥ Testing | Document processing, Scan service validation | **NEXT** |
| FASE 7-8 | 0% | Cloud Tasks, Monitoring, Production validation | Future |

### üöÄ WHAT'S READY NOW (Dec 26, 22:30)

‚úÖ **Infrastructure & Code:**
- All 14 Docker containers build and run locally (fresh rebuild verified)
- pg8000 database driver unified across all modules (pg8000_wrapper.py in place)
- Database: Cloud SQL TEST + PROD initialized with schemas
- GitHub Actions pipeline.yml configured and ready (single file, 3 conditional jobs)
- All GCP secrets and credentials configured

‚úÖ **Next Action - SIMPLE 3-STEP PROCESS:**
1. **Push to re_deploy_start** ‚Üí GitHub Actions pipeline.yml:build triggers automatically
2. **Build completes** ‚Üí pipeline.yml:deploy-test triggers automatically (no approval needed)
3. **TEST Cloud Run services live** ‚Üí Verify API/Frontend connectivity, then merge to main for PROD

**Current Blockers:** NONE - System is fully ready for deployment

---

## üéØ FOKUS JUST NU - December 26, 2025 (16:40)

**FASE 5 √§r COMPLETE:** API & Frontend deployed till Cloud Run TEST ‚úÖ

### Vad som √§r gjort ‚úÖ
- ‚úÖ Cloud Run TEST deployment working (API 00048, Frontend deployed)
- ‚úÖ JSON serialization fixed (PG8000DictRow ‚Üí dict conversion)
- ‚úÖ `company_enabled` field added to user API responses
- ‚úÖ Session cookies environment-aware (HTTPS in Cloud Run)
- ‚úÖ VPC Access Connectors configured for Private IP Cloud SQL
- ‚úÖ Email service disabled (temporary - pending SendGrid migration)
- ‚úÖ Admin user management fully functional (Enable/Disable buttons working)
- ‚úÖ Company management functional (Disable button tested, Enable pending company status)

### K√§nd begr√§nsning ‚ö†Ô∏è
- Email: Disabled i Cloud Run TEST (SMTP kan inte n√• Gmail fr√•n Cloud Run)
  - Temporary fix: Returns success without sending
  - Long-term: Migrate to SendGrid API
  - Location: `invoice.scanner.api/lib/email_service.py` line 1 (TODO comment in place)

### N√§sta steg üëâ
**FASE 6: Document Processing / Scan Service Testing**
1. Test document upload via frontend
2. Verify processing service triggers correctly
3. Check vectorstore integration (Chroma)
4. Validate document retrieval

**Blockers:** None - System is fully operational for testing

### Git Status
- Branch: `re_deploy_start` 
- Commits ahead: Latest fixes pushed (email disable, company_enabled fields)
- Ready to: Test FASE 6 (processing) or merge to main for PROD



## Projekt-specifikt

### Invoice Scanner - Core Info
- **Repo:** https://github.com/Rickard-E-Strawbay/invoice.scanner
- **Branches:** main (PROD) ‚Üê PR ‚Üê re_deploy_start (TEST)
- **Architecture:** API (Flask) + Frontend (React) + Workers (Celery)
- **Docker:** docker-compose.yml (single source of truth)
- **Deployment:** GitHub Actions (auto-builds + auto-deploys)

### Filer ALDRIG √§ndra utan att fr√•ga:
- `.github/workflows/pipeline.yml`
- docker-compose.yml (infrastruktur)
- Hele config-system (invoice.scanner.api/config/)
- .env-filer (anv√§nd GCP Secret Manager ist√§llet)

---

## ‚ö†Ô∏è AI-ASSISTENTENS KRITISKA INSTRUKTIONER

### √ñVERSTA PRIORITET - L√§s innan du g√∂r n√•got
1. **L√ÑSA DENNA FIL** innan n√•gon operation
2. **FR√ÖGA innan komplexitet** - inte bara implementera
3. **RESPEKTERA befintliga decisions** - inte √∂verskriv
4. **TESTA lokalt innan Cloud** - docker-compose f√∂rst

### REGLER SOM M√ÖSTE F√ñLJAS
- ‚úÖ **ALDRIG** skapa docker-compose files utan att fr√•ga
- ‚úÖ **ALDRIG** √§ndra .github/workflows/pipeline.yml utan att fr√•ga
- ‚úÖ **ALDRIG** manuellt deploy till Cloud Run (pipeline g√∂r det)
- ‚úÖ **ALDRIG** manuellt build till GCP registries (pipeline g√∂r det)
- ‚úÖ **FR√ÖGA F√ñRST** innan √§ndringar i GCP Secret Manager
- ‚úÖ **FR√ÖGA F√ñRST** innan √§ndringar i Cloud SQL config

### V√ÖR PROCESS (ej pipeline)
1. L√§s vad som redan finns (`ls`, `grep`, `git log`)
2. F√∂rst√• arkitekturen
3. Fr√•ga anv√§ndaren: "Vill du att jag ska [X] eller [Y]?"
4. Plan + dokumentera
5. Test lokalt (docker-compose)
6. Verifiera git diff
7. Commit med kontext

### BEFINTLIGA DECISIONS - RESPEKTERA
| Decision | Varf√∂r | √Ñndra INTE |
|----------|--------|-----------|
| pg8000 driver | Cloud SQL Connector kr√§vs | Inte psycopg2 |
| DATABASE_* vars | Standardiserad naming | Inte DB_* mix |
| Single pipeline.yml | Clean + maintainable | Inte 3 files |
| Cloud SQL Private IP | S√§kerhet | Inte public |
| RealDictCursor wrapper | Backward compatibility | Inte raw pg8000 |
| docker-compose.yml | Source of truth | Inte .local variant |

### VID PROBLEM
Ordning: Logs (GitHub Actions) ‚Üí Logs (Cloud Run) ‚Üí Logs (Cloud SQL) ‚Üí FIX KOD ‚Üí RE-PUSH

## Anv√§ndarens Preferenser
- Vill ha ENKLA l√∂sningar f√∂rst
- Vill att jag ska FR√ÖGA innan komplexitet
- Gillar TYDLIGA instruktioner
- Vill F√ñRST√Ö vad som g√∂rs, inte bara att det g√∂rs
- **VIKTIGAST:** Trust the pipeline - det √§r korrekt konfigurerat

---

## GCP DEPLOYMENT - √ñVERGRIPANDE ARKITEKTUR

### Enkel fl√∂de (Branch ‚Üí Deploy)

```
feature branch ‚Üí PR ‚Üí re_deploy_start (merge)
  ‚Üì
  Pipeline.yml:build (auto-trigger)
    - Auto-detects branch
    - Uses GCP_SA_KEY_TEST
    - Builds 3 images (API, Frontend, Worker)
    - Pushs to TEST Artifact Registry
  ‚Üì
  Pipeline.yml:deploy-test (auto-trigger)
    - Fetches TEST secrets from Secret Manager
    - Deploys API + Frontend to Cloud Run TEST
    - Runs smoke tests
  ‚Üì
  ‚úÖ TEST Cloud Run services live


main branch deployment (manual approval):
  ‚Üì
  Create PR: re_deploy_start ‚Üí main
  ‚Üì
  Pipeline.yml:build (auto-trigger)
    - Uses GCP_SA_KEY_PROD
    - Builds to PROD Artifact Registry
  ‚Üì
  Pipeline.yml:deploy-prod (waits for approval)
    - ‚ö†Ô∏è MANUAL APPROVAL GATE (24h timeout)
    - After approval: Fetches PROD secrets
    - Deploys to Cloud Run PROD
  ‚Üì
  ‚úÖ PROD Cloud Run services live
```

### Secrets Mapping

**TEST-projekt ‚Üí Environment Variables:**
```
db_user_test ‚Üí DATABASE_USER
db_password_test ‚Üí DATABASE_PASSWORD
secret_key_test ‚Üí FLASK_SECRET_KEY
gmail_sender ‚Üí EMAIL_SENDER
gmail_password ‚Üí EMAIL_PASSWORD
openai_api_key ‚Üí OPENAI_API_KEY
```

**PROD-projekt ‚Üí samma pattern** (med _prod suffixes)

### Key Architecture Points
- ‚úÖ **Private Cloud SQL** - Private IP + Cloud SQL Auth Proxy sidecar
- ‚úÖ **Centralized Secrets** - GCP Secret Manager (not in code)
- ‚úÖ **pg8000 Driver** - Pure Python (Cloud SQL Connector compatible)
- ‚úÖ **Single Pipeline** - `.github/workflows/pipeline.yml` (not 3 separate files)
- ‚úÖ **Branch Detection** - Auto-selects TEST vs PROD based on branch

---

## CI/CD PIPELINE - SIMPLIFIED

**File:** `.github/workflows/pipeline.yml` (single file, 3 conditional jobs - FINAL)

**How it works:**
1. **push to re_deploy_start** ‚Üí build job (auto) ‚Üí deploy-test job (auto)
2. **push to main** ‚Üí build job (auto) ‚Üí deploy-prod job (waits for manual approval)

**Each branch gets right secrets:**
- re_deploy_start: GCP_SA_KEY_TEST ‚Üí TEST Artifact Registry ‚Üí TEST Cloud Run
- main: GCP_SA_KEY_PROD ‚Üí PROD Artifact Registry ‚Üí PROD Cloud Run

**That's it!** The pipeline handles everything (building, pushing, deploying).

---

---

## IMPLEMENTATION CHECKLISTA

### FASE 0: Setup (N√ÑSTA - 0% done)
- [ ] GCP Project IDs dokumenterade
- [ ] Aktivera APIs: Cloud Run, Cloud SQL, Artifact Registry, Secret Manager, Cloud Tasks
- [ ] Service Accounts skapade (test + prod)
- [ ] GitHub Secrets konfigurerad: `GCP_SA_KEY`

### FASE 1: GCP Secret Manager (0% done)
- [ ] Skapa secrets i GCP Secret Manager (test project):
  - `db_password`, `db_user`, `api_key`, `gmail_password`, etc.
- [ ] Samma secrets i prod project
- [ ] Testa l√§sning fr√•n GitHub Actions

### FASE 2: Cloud SQL Setup (0% done)
- [ ] Skapa PostgreSQL instans (test)
  - Name: `invoice-scanner-test`
  - Network: Private IP
- [ ] Skapa PostgreSQL instans (prod)
  - Name: `invoice-scanner-prod`
  - Backup enabled
- [ ] K√∂r init.sql p√• b√•da
- [ ] Verifiera anslutning fr√•n Cloud Run

### FASE 3: Docker Images ‚úÖ 100% KLART

**Docker Images Built & Pushed to Artifact Registry:**

TEST-projekt (`strawbayscannertest`):
```
‚úÖ europe-west1-docker.pkg.dev/strawbayscannertest/invoice-scanner/api:latest
‚úÖ europe-west1-docker.pkg.dev/strawbayscannertest/invoice-scanner/frontend:latest
‚úÖ europe-west1-docker.pkg.dev/strawbayscannertest/invoice-scanner/worker:latest
```

PROD-projekt (`strawbayscannerprod`):
```
‚úÖ europe-west1-docker.pkg.dev/strawbayscannerprod/invoice-scanner/api:latest
‚úÖ europe-west1-docker.pkg.dev/strawbayscannerprod/invoice-scanner/frontend:latest
‚úÖ europe-west1-docker.pkg.dev/strawbayscannerprod/invoice-scanner/worker:latest
```

**Image Details:**
- API: 1.44 GB (python:3.11-slim, Flask, optimized dependencies)
- Frontend: 83.1 MB (Node 20-alpine builder + nginx multi-stage)
- Worker: 4.02 GB (python:3.11-bullseye + OCR dependencies)

**Pushed:** Dec 24, 2025
**Status:** All 6 images successfully pushed to both registries

### FASE 4: GitHub Actions Workflows ‚úÖ 100% KLART

**Single Unified Pipeline:** `.github/workflows/pipeline.yml`
- ‚úÖ build job - Detects branch, builds 3 images, pushes to correct registry
- ‚úÖ deploy-test job - Conditional on re_deploy_start, no approval needed
- ‚úÖ deploy-prod job - Conditional on main, requires `environment: production` approval
- ‚úÖ All 3 jobs in one file for maintainability
- ‚úÖ Branch detection logic in build job first step
- ‚úÖ Jobs properly chain with `needs: build` dependency
- ‚úÖ Uses secrets: `GCP_SA_KEY_TEST` or `GCP_SA_KEY_PROD` (auto-selected)

**Cleanup completed:**
- ‚úÖ Removed old build.yml, test-deploy.yml, prod-deploy.yml
- ‚úÖ Removed .bak backup files
- ‚úÖ Workflows directory now contains ONLY pipeline.yml
- ‚úÖ Committed and pushed to origin/re_deploy_start

**Status:** All 3 conditional jobs ready to execute on branch push

**What's needed:**
- ‚è≥ User creates PR on re_deploy_start to test
- ‚è≥ First merge to re_deploy_start (pipeline.yml:build + pipeline.yml:deploy-test run)
- ‚è≥ First merge to main (pipeline.yml:build + pipeline.yml:deploy-prod with approval)

---

## DATABASE MIGRATION STRATEGY (DECIDED Dec 26)

**Decision:** Use **Versionalized SQL Migrations** approach for future database changes

### How it works:
- Each database change gets its own versioned SQL file: `migrations/001_initial.sql`, `002_add_column_x.sql`, etc.
- Files are named: `{number}_{description}.sql` (e.g., `001_initial.sql`, `002_add_invoices_table.sql`)
- Run migrations in order (only once per environment)
- Track which migrations have run in a `schema_migrations` table

### Initial Setup (Dec 26 - COMPLETED):
- [x] ‚úÖ Run `invoice.scanner.db/init.sql` manually on Cloud SQL TEST
- [x] ‚úÖ Verify: Check that users table has test user (rickard@strawbay.io)
- [x] ‚úÖ Run same init.sql on PROD after TEST is verified

### Future Database Changes:
1. Create new file: `migrations/002_your_change.sql`
2. Document what changed
3. Run it manually on TEST first
4. After verification, run on PROD
5. Add to git + commit

### Directory Structure:
```
invoice.scanner.db/
‚îú‚îÄ‚îÄ init.sql (initial schema + seed data)
‚îî‚îÄ‚îÄ migrations/
    ‚îú‚îÄ‚îÄ 002_add_feature_x.sql
    ‚îú‚îÄ‚îÄ 003_update_permissions.sql
    ‚îî‚îÄ‚îÄ ...
```

---

## CLOUD SQL PROXY CONFIGURATION (DECIDED Dec 26)

**Problem (Dec 26 08:15):** Cloud Run API couldn't connect to Cloud SQL
- Error: `connection to server at "invoice-scanner-test.c.strawbayscannertest.cloudsql.googleapis.com" port 5432 failed: Connection timed out`
- Root cause: Cloud SQL is Private IP only, API tried public hostname

**Solution:** Cloud SQL Auth Proxy sidecar in Cloud Run
- Already configured in pipeline.yml with `--add-cloudsql-instances` flag
- Creates secure tunnel from Cloud Run container to Cloud SQL
- Exposes connection on `localhost:5432`

**Implementation (Dec 26):**
1. ‚úÖ pipeline.yml already has `--add-cloudsql-instances` flag in both deploy-test and deploy-prod
2. ‚úÖ Changed DATABASE_HOST from `invoice-scanner-test.c.strawbayscannertest.cloudsql.googleapis.com` to `localhost`
3. ‚úÖ Same for PROD: `invoice-scanner-prod.c.strawbayscannerprod.cloudsql.googleapis.com` ‚Üí `localhost`
4. Rationale: Cloud SQL Proxy maps port 5432 to localhost internally

**Environment Variables in Cloud Run:**
```
TEST:
  DATABASE_HOST=localhost (with Cloud SQL Proxy sidecar)
  DATABASE_PORT=5432
  DATABASE_USER=scanner_test
  DATABASE_PASSWORD=(from Secret Manager)
  DATABASE_NAME=invoice_scanner

PROD: (same pattern)
  DATABASE_HOST=localhost
  DATABASE_PORT=5432
  DATABASE_USER=scanner_prod
  DATABASE_PASSWORD=(from Secret Manager)
  DATABASE_NAME=invoice_scanner
```

**How it works:**
1. Cloud Run container starts with `--add-cloudsql-instances=project:region:instance`
2. Google Cloud Proxy sidecar automatically starts (injected by Cloud Run)
3. Proxy creates secure connection to Cloud SQL (Private IP)
4. Proxy listens on `localhost:5432` inside container
5. Application connects to `localhost:5432` (authenticated via Cloud Run service account)

**Reference:**
- [Google Cloud SQL Auth Proxy Docs](https://cloud.google.com/sql/docs/postgres/sql-proxy)
- [Cloud Run + Cloud SQL Integration](https://cloud.google.com/run/docs/configuring/sql-connectors)

**Status:** ‚úÖ CONFIGURED in pipeline.yml (both TEST and PROD)

---

## VPC ACCESS CONNECTOR (REQUIRED FOR PRIVATE IP) - Dec 26

**Problem Discovered:** 
- Cloud SQL instances are Private IP only (secure by default)
- Cloud Run services need special networking to reach Private IP
- Error without VPC Connector: `Cloud SQL instance does not have any IP addresses matching preference: PRIMARY`

**Solution:** VPC Access Connector
- Creates a managed VPC connector between Cloud Run and VPC (where Cloud SQL lives)
- Allows Cloud Run to reach Private IP resources securely
- Must be in same region as Cloud Run (europe-west1)

**Implementation (REQUIRED - Must Run Manually):**

### Step 1: Create VPC Access Connector (one-time setup)
```bash
gcloud compute networks vpc-access connectors create run-connector \
  --region=europe-west1 \
  --network=default \
  --range=10.8.0.0/28 \
  --project=strawbayscannertest
```

### Step 2: Update Cloud Run Services to Use Connector (TEST environment)
```bash
gcloud run services update invoice-scanner-api-test \
  --region=europe-west1 \
  --vpc-connector=run-connector \
  --vpc-egress=all \
  --project=strawbayscannertest

gcloud run services update invoice-scanner-frontend-test \
  --region=europe-west1 \
  --vpc-connector=run-connector \
  --vpc-egress=all \
  --project=strawbayscannertest
```

### Step 3: Update Cloud Run Services to Use Connector (PROD environment)
```bash
gcloud compute networks vpc-access connectors create run-connector \
  --region=europe-west1 \
  --network=default \
  --range=10.8.0.0/28 \
  --project=strawbayscannerprod

gcloud run services update invoice-scanner-api-prod \
  --region=europe-west1 \
  --vpc-connector=run-connector \
  --vpc-egress=all \
  --project=strawbayscannerprod

gcloud run services update invoice-scanner-frontend-prod \
  --region=europe-west1 \
  --vpc-connector=run-connector \
  --vpc-egress=all \
  --project=strawbayscannerprod
```

**Why this works:**
- VPC Connector bridges Cloud Run ‚Üî VPC network
- Cloud SQL Private IP exists in VPC
- Cloud Run can now reach Private IP via connector
- `--vpc-egress=all` routes all outbound traffic through connector

**Status:** ‚úÖ IMPLEMENTED Dec 26 (manually for TEST, must repeat for PROD)

**In pipeline.yml:** 
- Consider adding VPC connector setup to deploy-test/deploy-prod jobs if possible
- Alternative: Document as manual post-deployment step

---

## DATABASE DRIVER STRATEGY: pg8000 Migration (DECIDED Dec 26)

### Problem Discovery (Dec 26 - CRITICAL)

**Error in Cloud Run logs (10:00:39):**
```
"Driver 'psycopg2' is not supported."
```

**Root Cause Investigation:**
- Cloud SQL Connector API documentation discovered: Only supports `pymysql`, `pg8000`, `pytds`
- psycopg2 is NOT supported by Cloud SQL Connector
- Current code attempted: `connector.connect(..., "psycopg2", ...)`
- This was doomed to fail in Cloud Run

**Architecture Issue (SIMULTANEOUS DISCOVERY):**
- API uses `DATABASE_*` environment variables
- Processing uses `DB_*` environment variables (old naming convention)
- Two separate database connection systems in same project
- Cannot fix one without fixing both

### Solution: Unified pg8000 Strategy

**Why pg8000?**
- ‚úÖ Pure Python PostgreSQL driver (no C dependencies)
- ‚úÖ Cloud SQL Connector officially supports it
- ‚úÖ Works with local TCP connections (docker-compose)
- ‚úÖ Works with future Connector mode in Cloud Run
- ‚úÖ Single solution for all environments

**Challenges:**
- pg8000 doesn't have `RealDictCursor` built-in (like psycopg2)
- Current codebase heavily uses RealDictCursor for dictionary-like row access
- Solution: Create wrapper layer providing RealDictCursor interface for pg8000

### Implementation Plan (3-Part Refactoring)

**Part 1: Create Shared Database Abstraction Layer**
- Location: `/shared/pg8000_wrapper.py`
- Provides: `RealDictCursor`-like interface for pg8000 rows
- Supports: Both local TCP (docker-compose) and future Connector mode (Cloud Run)
- Implements: Connection pooling for efficiency

**Part 2: Standardize Environment Variables Across Entire Project**
- Converge: `DB_*` variables ‚Üí `DATABASE_*` (uniform naming)
- Files affected:
  - `invoice.scanner.api/db_config.py` - Already uses DATABASE_*
  - `invoice.scanner.api/db_utils.py` - Uses db_config imports
  - `invoice.scanner.processing/config/db_utils.py` - Uses old DB_* (needs update)
  - `docker-compose.yml` - Update all 13 services to use DATABASE_*
- Rationale: Single naming convention simplifies debugging + matches Cloud Run

**Part 3: Update Both API and Processing Modules**
- API: Refactor db_config.py to use shared pg8000 wrapper
- Processing: Update config/db_utils.py to use shared wrapper + new env vars
- Verify: All existing functionality preserved (RealDictCursor behavior replicated)
- Test: All 13 containers work locally before Cloud Run

### Critical Instructions (Must Remember)

**When implementing pg8000 migration:**

1. **INVESTIGATE FIRST**
   - Grep for all uses of `psycopg2.connect()`
   - Find all places using `RealDictCursor`
   - Check all environment variable references
   - Understand current connection patterns

2. **STANDARDIZE NAMING SYSTEMATICALLY**
   - Don't leave dual naming convention (mixing DATABASE_* and DB_*)
   - Update docker-compose.yml simultaneously
   - Verify all 13 containers get correct variables
   - No half-migrations

3. **TEST LOCALLY BEFORE CLOUD RUN**
   - Run all 13 containers with new pg8000 wrapper
   - Test API login endpoint (uses database)
   - Test processing workers (use database queries)
   - Verify RealDictCursor compatibility layer works

4. **MAINTAIN BACKWARD COMPATIBILITY**
   - Existing code should not know it's pg8000 internally
   - RealDictCursor interface must be identical to psycopg2 version
   - All cursors should still behave like dictionaries

### Current Status (Dec 26 - Migration Complete ‚úÖ)

**Completed (ALL):**
- ‚úÖ Identified driver incompatibility (psycopg2 not supported by Cloud SQL Connector)
- ‚úÖ Analyzed entire project structure (unified pg8000 approach)
- ‚úÖ Created pg8000_wrapper.py with RealDictCursor compatibility in API and Processing
- ‚úÖ Updated requirements.txt: Removed psycopg2-binary, added pg8000
- ‚úÖ API db_config.py configured for pg8000 (DATABASE_* variables)
- ‚úÖ Processing config/db_utils.py configured for pg8000 (DATABASE_* variables)
- ‚úÖ docker-compose.yml standardized to DATABASE_* naming (no DB_* mixing)
- ‚úÖ Local testing: all 14 containers healthy, database connections working
- ‚úÖ Document processing verified (status updates working correctly)
- ‚úÖ Git commit with detailed migration message (commit: 03db1c6)

**Status:** READY FOR CLOUD RUN DEPLOYMENT
- All components use unified pg8000 driver
- Both local (docker-compose) and Cloud Run (via Connector) compatible
- RealDictCursor compatibility maintained for existing code
- No psycopg2 dependencies remaining

---

### FASE 5: Cloud Run TEST Deployment (NEXT - Ready to Start)

**Status:** ‚úÖ All prerequisites complete - Ready for GitHub Actions pipeline

**Steps to execute:**
- [ ] 1. Verify local: `docker-compose down && docker-compose up -d --build` (DONE ‚úÖ)
- [ ] 2. Commit any pending changes: `git add . && git commit -m "..."`
- [ ] 3. Push to re_deploy_start: `git push origin re_deploy_start`
- [ ] 4. Monitor GitHub Actions: https://github.com/Rickard-E-Strawbay/invoice.scanner/actions
  - build job runs (~5-10 min): builds api, frontend, worker images
  - deploy-test job runs (~3-5 min): deploys to Cloud Run TEST
  - Both jobs should complete successfully with smoke tests passing
- [ ] 5. After deployment: Test API/Frontend on Cloud Run TEST URLs
- [ ] 6. Create PR: re_deploy_start ‚Üí main (for PROD deployment)
- [ ] 7. After PROD PR approval: Merge to main (pipeline.yml:deploy-prod with manual approval gate)

### FASE 6: Cloud Tasks Setup (0% done)
- [ ] Konfigurera Cloud Tasks queue f√∂r workers
- [ ] Cloud Pub/Sub topics f√∂r events
- [ ] Worker-container ready f√∂r on-demand execution

### FASE 7: Testing & Verification (0% done)
- [ ] Test pipeline fr√•n GitHub push
- [ ] Manual approval flow testat
- [ ] Smoke tests p√• Cloud Run services
- [ ] Database connectivity verified
- [ ] Secrets l√§ses korrekt

### FASE 8: Monitoring & Alerts (0% done)
- [ ] Google Cloud Logging configured
- [ ] Error alerts setup
- [ ] Performance monitoring
- [ ] Backup verification (prod)

---

## GCP PROJEKT KONFIGURATION

**GCP Project IDs:**
- ‚úÖ Test: `strawbayscannertest`
- ‚úÖ Prod: `strawbayscannerprod`

**Region:**
- ‚úÖ `europe-west1` (Belgien)

**URLs:**
- ‚úÖ GCP-genererade URLs (ex: `api-xxxxx.run.app`)

## GCP SECRETS STRATEGI (GODK√ÑND)

**GitHub Secrets (Option A - Tv√• separata):**
- `GCP_SA_KEY_TEST` ‚Üí Service Account JSON fr√•n TEST-projekt
- `GCP_SA_KEY_PROD` ‚Üí Service Account JSON fr√•n PROD-projekt

**Varf√∂r tv√•:** CI/CD pipeline kan automatiskt v√§lja r√§tt secret baserat p√• milj√∂ (test branch ‚Üí TEST secret, main branch ‚Üí PROD secret)

**S√§kerhet:**
- ‚úÖ Aldrig lagra secrets i kod
- ‚úÖ GitHub Secrets √§r encrypted
- ‚úÖ Loggar visar inte secret-v√§rden
- ‚úÖ Endast Actions kan l√§sa secrets under k√∂rning

---

## GCP SETUP STATUS - FASE 0: ‚úÖ 100% KLART

**APIs Aktiverade: ‚úÖ KLART**
- ‚úÖ TEST-projekt: Alla 5 APIs enabled
- ‚úÖ PROD-projekt: Alla 5 APIs enabled

**Service Accounts: ‚úÖ KLART**
- ‚úÖ TEST-projekt: `github-deployer` skapad (Editor role)
- ‚úÖ PROD-projekt: `github-deployer` skapad (Editor role)

**JSON-Nycklar: ‚úÖ KLART**
- ‚úÖ TEST-projekt: JSON-nyckel nedladdad
- ‚úÖ PROD-projekt: JSON-nyckel nedladdad

**GitHub Secrets: ‚úÖ KLART**
- ‚úÖ `GCP_SA_KEY_TEST` ‚Üí Ligger i GitHub
- ‚úÖ `GCP_SA_KEY_PROD` ‚Üí Ligger i GitHub

**Progress FASE 0:**
- ‚úÖ [x] APIs aktiverade (test + prod)
- ‚úÖ [x] Service Accounts skapade (test + prod)
- ‚úÖ [x] JSON-nycklar exporterade (test + prod)
- ‚úÖ [x] GitHub Secrets konfigurerad (Option A)

---

## IMPLEMENTATION CHECKLISTA - UPPDATERAD

### FASE 0: Setup ‚úÖ KLART (100%)
- ‚úÖ GCP Project IDs dokumenterade
- ‚úÖ Aktivera APIs: Cloud Run, Cloud SQL, Artifact Registry, Secret Manager, Cloud Tasks
- ‚úÖ Service Accounts skapade (test + prod)
- ‚úÖ GitHub Secrets konfigurerad: `GCP_SA_KEY_TEST` + `GCP_SA_KEY_PROD`

### FASE 1: GCP Secret Manager ‚úÖ KLART (100%)

**Database Credentials: ‚úÖ SKAPADE I GCP SECRET MANAGER**

TEST-projekt (`strawbayscannertest`) secrets:
- ‚úÖ `db_user_test` = `scanner_test`
- ‚úÖ `db_password_test` = `3ksaMsUqY5EW60FvXmp5MNv9i!mbkoQX`

PROD-projekt (`strawbayscannerprod`) secrets:
- ‚úÖ `db_user_prod` = `scanner_prod`
- ‚úÖ `db_password_prod` = `94LVGuefzk0g#a4Mbu2u!mu@I7R%PItl`

**Flask SECRET_KEY: ‚úÖ SKAPADE**

TEST-projekt:
- ‚úÖ `secret_key_test` = `cWz$o%u-Mnfse1k%bhNf3K_xRcvSeFxnHlQzgt5H!wSWYtliIB4COYyKNq7iq7Gi`

PROD-projekt:
- ‚úÖ `secret_key_prod` = `kWKmBqNA@7WSERqjAP%E8X6ulY%cvX!!j6hUQ8DgiZqCyjq8Ag@4OTEXhx5P9LWz`

**Email Credentials: ‚úÖ SKAPADE (samma i b√•de test och prod)**

B√ÖDA projekt:
- ‚úÖ `gmail_sender` = `rickard@strawbay.io`
- ‚úÖ `gmail_password` = `ggse prtk gmye nrqe`

**LLM API Keys: ‚úÖ SKAPADE (samma i b√•de test och prod)**

B√ÖDA projekt:
- ‚úÖ `openai_api_key` = (fr√•n Secret Manager)

**Summa FASE 1:**
- ‚úÖ 6 secrets i TEST-projekt
- ‚úÖ 6 secrets i PROD-projekt
- ‚úÖ Alla anv√§ndaruppgifter fr√•n befintlig `.env` migrerade
- ‚úÖ Starka, genererade l√∂senord f√∂r databaskonton
- ‚úÖ Starka, genererade Flask SECRET_KEY f√∂r b√•da milj√∂er

### FASE 2: Cloud SQL Setup ‚úÖ KLART (100%)

**TEST-projekt (`strawbayscannertest`): ‚úÖ KLART**

PostgreSQL Instans:
- ‚úÖ Instance name: `invoice-scanner-test`
- ‚úÖ Machine type: db-f1-micro (Shared-core, 0.614 GB RAM)
- ‚úÖ Region: europe-west1 (belgien)
- ‚úÖ Private IP: Enabled
- ‚úÖ Database: `invoice_scanner` skapad
- ‚úÖ User: `scanner_test` skapad
- ‚úÖ Root password: `0R@UMO1Mr-s-hKVA6Y5JwSWQUrcIY1RN`

**PROD-projekt (`strawbayscannerprod`): ‚úÖ KLART**

PostgreSQL Instans:
- ‚úÖ Instance name: `invoice-scanner-prod`
- ‚úÖ Machine type: db-f1-micro (Shared-core)
- ‚úÖ Region: europe-west1
- ‚úÖ Private IP: Enabled
- ‚úÖ Backup: Enabled
- ‚úÖ Database: `invoice_scanner` skapad
- ‚úÖ User: `scanner_prod` skapad
- ‚úÖ Root password: `HP!#mtYvvxmGxgvJP7AynwmlBvFyGd_r`

### FASE 3: Docker Images (0% done)
- [ ] Dockerfile API: Ready f√∂r Cloud Run
- [ ] Dockerfile Frontend: Ready f√∂r Cloud Run
- [ ] Dockerfile Worker: Ready f√∂r Cloud Tasks
- [ ] Build & push till Artifact Registry (test f√∂rst)

### FASE 4: GitHub Actions Workflows (100% KLART)
- ‚úÖ `.github/workflows/pipeline.yml` - Single file with build + conditional deploys
- ‚úÖ build job - Auto-detects branch, builds 3 images, pushes to correct registry
- ‚úÖ deploy-test job - Runs on re_deploy_start (no approval)
- ‚úÖ deploy-prod job - Runs on main (requires approval)
- ‚úÖ All jobs in one unified file

### FASE 5: Cloud Run Deployment (0% done)
- [ ] Deploy API service (test)
  - Environment variables fr√•n Secret Manager
  - Cloud SQL proxy
- [ ] Deploy Frontend service (test)
  - Build from Docker image
- [ ] Setup Cloud Storage bucket (documents)
- [ ] Samma setup f√∂r prod

### FASE 6: Cloud Tasks Setup (0% done)
- [ ] Konfigurera Cloud Tasks queue f√∂r workers
- [ ] Cloud Pub/Sub topics f√∂r events
- [ ] Worker-container ready f√∂r on-demand execution

### FASE 7: Testing & Verification (0% done)
- [ ] Test pipeline fr√•n GitHub push
- [ ] Manual approval flow testat
- [ ] Smoke tests p√• Cloud Run services
- [ ] Database connectivity verified
- [ ] Secrets l√§ses korrekt

### FASE 8: Monitoring & Alerts (0% done)
- [ ] Google Cloud Logging configured
- [ ] Error alerts setup
- [ ] Performance monitoring
- [ ] Backup verification (prod)

---

### TEST-Projektet (`strawbayscannertest`)

**Aktiverade APIs:**
- ‚úÖ Cloud Run Admin API
- ‚úÖ Cloud SQL Admin API
- ‚úÖ Artifact Registry API
- ‚úÖ Secret Manager API
- ‚úÖ Cloud Tasks API

**Service Accounts:**
- ‚úÖ `github-deployer` (Editor role) - Beh√∂ver JSON-nyckel

**Kommande:**
- ‚è≥ JSON-nyckel exporterad
- ‚è≥ Cloud SQL PostgreSQL instans
- ‚è≥ Cloud Storage bucket
- ‚è≥ Secret Manager secrets

---

### PROD-Projektet (`strawbayscannerprod`)

**Aktiverade APIs:**
- ‚úÖ Cloud Run Admin API
- ‚úÖ Cloud SQL Admin API
- ‚úÖ Artifact Registry API
- ‚úÖ Secret Manager API
- ‚úÖ Cloud Tasks API

**Service Accounts:**
- ‚úÖ `github-deployer` (Editor role) - Beh√∂ver JSON-nyckel

**Kommande:**
- ‚è≥ JSON-nyckel exporterad
- ‚è≥ Cloud SQL PostgreSQL instans (med backup)
- ‚è≥ Cloud Storage bucket
- ‚è≥ Secret Manager secrets

---

**Summa:** Unders√∂k, Fr√•ga, Skapa. Inte: Skapa, Skapa, Skapa, sedan r√§tta allt.
